{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L(mm)</th>\n",
       "      <th>W(mm)</th>\n",
       "      <th>h(mm)</th>\n",
       "      <th>Er</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   L(mm)  W(mm)  h(mm)   Er     f\n",
       "0   20.0   26.0   1.60  4.4  3.46\n",
       "1   20.0   26.0   1.20  4.4  3.74\n",
       "2   20.0   26.0   1.25  4.4  3.68\n",
       "3   20.0   26.0   1.30  4.4  3.51\n",
       "4   20.0   26.0   1.35  4.4  3.55\n",
       "5   20.0   26.0   1.40  4.4  3.48\n",
       "6   20.0   26.0   1.45  4.4  3.62\n",
       "7   20.0   26.0   1.50  4.4  3.50\n",
       "8   20.0   26.0   1.55  4.4  3.42\n",
       "9   20.0   26.0   1.60  4.4  3.48"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('antenna.xlsx')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L(mm)</th>\n",
       "      <th>W(mm)</th>\n",
       "      <th>h(mm)</th>\n",
       "      <th>Er</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>22.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>21.30</td>\n",
       "      <td>29.30</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>20.50</td>\n",
       "      <td>26.50</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>21.20</td>\n",
       "      <td>27.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.40</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>23.65</td>\n",
       "      <td>31.65</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>19.75</td>\n",
       "      <td>27.75</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>22.90</td>\n",
       "      <td>30.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>23.95</td>\n",
       "      <td>31.95</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>20.70</td>\n",
       "      <td>28.70</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>18.35</td>\n",
       "      <td>26.35</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>23.15</td>\n",
       "      <td>31.15</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.55</td>\n",
       "      <td>26.55</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>20.40</td>\n",
       "      <td>28.40</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>23.90</td>\n",
       "      <td>31.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>18.95</td>\n",
       "      <td>26.95</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>19.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>22.80</td>\n",
       "      <td>30.80</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>20.70</td>\n",
       "      <td>26.70</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>21.30</td>\n",
       "      <td>27.30</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.55</td>\n",
       "      <td>29.55</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>18.90</td>\n",
       "      <td>26.90</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>19.45</td>\n",
       "      <td>27.45</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>20.85</td>\n",
       "      <td>28.85</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>22.20</td>\n",
       "      <td>30.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>21.70</td>\n",
       "      <td>27.70</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>23.45</td>\n",
       "      <td>31.45</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>23.55</td>\n",
       "      <td>31.55</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>22.20</td>\n",
       "      <td>28.20</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     L(mm)  W(mm)  h(mm)    Er\n",
       "18   20.00  26.00   2.05  4.40\n",
       "169  20.00  26.00   1.60  5.30\n",
       "106  22.00  30.00   1.60  4.40\n",
       "92   21.30  29.30   1.60  4.40\n",
       "176  20.50  26.50   1.60  4.40\n",
       "183  21.20  27.20   1.60  4.75\n",
       "5    20.00  26.00   1.40  4.40\n",
       "139  23.65  31.65   1.60  4.40\n",
       "12   20.00  26.00   1.75  4.40\n",
       "160  20.00  26.00   1.60  4.85\n",
       "61   19.75  27.75   1.60  4.40\n",
       "124  22.90  30.90   1.60  4.40\n",
       "164  20.00  26.00   1.60  5.05\n",
       "145  23.95  31.95   1.60  4.40\n",
       "80   20.70  28.70   1.60  4.40\n",
       "7    20.00  26.00   1.50  4.40\n",
       "33   18.35  26.35   1.60  4.40\n",
       "129  23.15  31.15   1.60  4.40\n",
       "37   18.55  26.55   1.60  4.40\n",
       "74   20.40  28.40   1.60  4.40\n",
       "159  20.00  26.00   1.60  4.80\n",
       "144  23.90  31.90   1.60  4.40\n",
       "45   18.95  26.95   1.60  4.40\n",
       "158  20.00  26.00   1.60  4.75\n",
       "60   19.70  27.70   1.60  4.40\n",
       "122  22.80  30.80   1.60  4.40\n",
       "178  20.70  26.70   1.60  4.50\n",
       "184  21.30  27.30   1.60  4.80\n",
       "97   21.55  29.55   1.60  4.40\n",
       "44   18.90  26.90   1.60  4.40\n",
       "16   20.00  26.00   1.95  4.40\n",
       "55   19.45  27.45   1.60  4.40\n",
       "83   20.85  28.85   1.60  4.40\n",
       "110  22.20  30.20   1.60  4.40\n",
       "22   20.00  26.00   2.25  4.40\n",
       "188  21.70  27.70   1.60  5.00\n",
       "135  23.45  31.45   1.60  4.40\n",
       "4    20.00  26.00   1.35  4.40\n",
       "137  23.55  31.55   1.60  4.40\n",
       "193  22.20  28.20   1.60  5.25"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18     3.40\n",
       "169    3.21\n",
       "106    3.09\n",
       "92     3.37\n",
       "176    3.45\n",
       "183    3.15\n",
       "5      3.48\n",
       "139    3.12\n",
       "12     3.47\n",
       "160    3.32\n",
       "61     3.47\n",
       "124    2.98\n",
       "164    3.24\n",
       "145    2.88\n",
       "80     3.11\n",
       "7      3.50\n",
       "33     3.85\n",
       "129    3.11\n",
       "37     3.79\n",
       "74     3.41\n",
       "159    3.41\n",
       "144    2.97\n",
       "45     3.62\n",
       "158    3.39\n",
       "60     3.49\n",
       "122    3.01\n",
       "178    3.38\n",
       "184    3.21\n",
       "97     3.48\n",
       "44     3.58\n",
       "16     3.52\n",
       "55     3.48\n",
       "83     3.47\n",
       "110    3.13\n",
       "22     3.58\n",
       "188    2.95\n",
       "135    2.91\n",
       "4      3.55\n",
       "137    2.91\n",
       "193    2.89\n",
       "Name: f, dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SC=StandardScaler()\n",
    "X_train=SC.fit_transform(X_train)\n",
    "X_test=SC.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "5/5 [==============================] - 1s 70ms/step - loss: 2.6686 - mse: 8.5129 - val_loss: 2.5325 - val_mse: 8.0878\n",
      "Epoch 2/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.4887 - mse: 7.7841 - val_loss: 2.5023 - val_mse: 7.8872\n",
      "Epoch 3/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5975 - mse: 8.1127 - val_loss: 2.4770 - val_mse: 7.6908\n",
      "Epoch 4/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5176 - mse: 7.6449 - val_loss: 2.4503 - val_mse: 7.4890\n",
      "Epoch 5/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.5003 - mse: 7.5011 - val_loss: 2.4202 - val_mse: 7.2795\n",
      "Epoch 6/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.2758 - mse: 6.6630 - val_loss: 2.3851 - val_mse: 7.0584\n",
      "Epoch 7/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.3336 - mse: 6.7869 - val_loss: 2.3477 - val_mse: 6.8270\n",
      "Epoch 8/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.3244 - mse: 6.7557 - val_loss: 2.3080 - val_mse: 6.5936\n",
      "Epoch 9/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.2762 - mse: 6.5309 - val_loss: 2.2643 - val_mse: 6.3617\n",
      "Epoch 10/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1392 - mse: 5.9438 - val_loss: 2.2163 - val_mse: 6.1224\n",
      "Epoch 11/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 2.1497 - mse: 6.0124 - val_loss: 2.1695 - val_mse: 5.8925\n",
      "Epoch 12/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.1133 - mse: 5.8961 - val_loss: 2.1207 - val_mse: 5.6723\n",
      "Epoch 13/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0719 - mse: 5.7517 - val_loss: 2.0733 - val_mse: 5.4628\n",
      "Epoch 14/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0540 - mse: 5.5987 - val_loss: 2.0255 - val_mse: 5.2583\n",
      "Epoch 15/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9747 - mse: 5.3176 - val_loss: 1.9777 - val_mse: 5.0622\n",
      "Epoch 16/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.9398 - mse: 5.2088 - val_loss: 1.9350 - val_mse: 4.8818\n",
      "Epoch 17/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9082 - mse: 4.9917 - val_loss: 1.8951 - val_mse: 4.7096\n",
      "Epoch 18/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.9681 - mse: 5.2694 - val_loss: 1.8574 - val_mse: 4.5372\n",
      "Epoch 19/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.8605 - mse: 4.7550 - val_loss: 1.8192 - val_mse: 4.3702\n",
      "Epoch 20/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7373 - mse: 4.4050 - val_loss: 1.7797 - val_mse: 4.2021\n",
      "Epoch 21/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.8131 - mse: 4.5551 - val_loss: 1.7407 - val_mse: 4.0418\n",
      "Epoch 22/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.6468 - mse: 4.0074 - val_loss: 1.7000 - val_mse: 3.8842\n",
      "Epoch 23/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7512 - mse: 4.3621 - val_loss: 1.6579 - val_mse: 3.7252\n",
      "Epoch 24/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.7101 - mse: 4.1673 - val_loss: 1.6131 - val_mse: 3.5576\n",
      "Epoch 25/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5966 - mse: 3.7958 - val_loss: 1.5694 - val_mse: 3.4006\n",
      "Epoch 26/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5759 - mse: 3.6661 - val_loss: 1.5235 - val_mse: 3.2410\n",
      "Epoch 27/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5992 - mse: 3.7096 - val_loss: 1.4772 - val_mse: 3.0835\n",
      "Epoch 28/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.5336 - mse: 3.5334 - val_loss: 1.4284 - val_mse: 2.9250\n",
      "Epoch 29/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.5321 - mse: 3.4949 - val_loss: 1.3792 - val_mse: 2.7698\n",
      "Epoch 30/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4725 - mse: 3.2837 - val_loss: 1.3307 - val_mse: 2.6144\n",
      "Epoch 31/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.4090 - mse: 3.0908 - val_loss: 1.2845 - val_mse: 2.4667\n",
      "Epoch 32/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.4328 - mse: 3.1712 - val_loss: 1.2385 - val_mse: 2.3280\n",
      "Epoch 33/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.3051 - mse: 2.7824 - val_loss: 1.1921 - val_mse: 2.2015\n",
      "Epoch 34/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.2732 - mse: 2.6642 - val_loss: 1.1489 - val_mse: 2.0793\n",
      "Epoch 35/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1107 - mse: 2.1281 - val_loss: 1.1042 - val_mse: 1.9626\n",
      "Epoch 36/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.1836 - mse: 2.3243 - val_loss: 1.0628 - val_mse: 1.8486\n",
      "Epoch 37/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0927 - mse: 2.0739 - val_loss: 1.0226 - val_mse: 1.7437\n",
      "Epoch 38/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.1202 - mse: 2.1461 - val_loss: 0.9794 - val_mse: 1.6410\n",
      "Epoch 39/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0742 - mse: 2.0056 - val_loss: 0.9416 - val_mse: 1.5451\n",
      "Epoch 40/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0270 - mse: 1.9196 - val_loss: 0.9047 - val_mse: 1.4487\n",
      "Epoch 41/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.0349 - mse: 1.8542 - val_loss: 0.8645 - val_mse: 1.3658\n",
      "Epoch 42/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 1.0190 - mse: 1.8034 - val_loss: 0.8304 - val_mse: 1.2916\n",
      "Epoch 43/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.9351 - mse: 1.6328 - val_loss: 0.7987 - val_mse: 1.2213\n",
      "Epoch 44/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9003 - mse: 1.5279 - val_loss: 0.7732 - val_mse: 1.1542\n",
      "Epoch 45/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8456 - mse: 1.3734 - val_loss: 0.7492 - val_mse: 1.0914\n",
      "Epoch 46/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8517 - mse: 1.3761 - val_loss: 0.7252 - val_mse: 1.0306\n",
      "Epoch 47/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7983 - mse: 1.2504 - val_loss: 0.7053 - val_mse: 0.9782\n",
      "Epoch 48/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.8407 - mse: 1.2890 - val_loss: 0.6890 - val_mse: 0.9288\n",
      "Epoch 49/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.8329 - mse: 1.2845 - val_loss: 0.6771 - val_mse: 0.8906\n",
      "Epoch 50/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7867 - mse: 1.1599 - val_loss: 0.6596 - val_mse: 0.8452\n",
      "Epoch 51/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7748 - mse: 1.1410 - val_loss: 0.6463 - val_mse: 0.8107\n",
      "Epoch 52/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7031 - mse: 0.9652 - val_loss: 0.6321 - val_mse: 0.7736\n",
      "Epoch 53/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.7153 - mse: 0.9754 - val_loss: 0.6180 - val_mse: 0.7389\n",
      "Epoch 54/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.6911 - mse: 0.8888 - val_loss: 0.6051 - val_mse: 0.7075\n",
      "Epoch 55/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6778 - mse: 0.8788 - val_loss: 0.5926 - val_mse: 0.6765\n",
      "Epoch 56/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6785 - mse: 0.8694 - val_loss: 0.5800 - val_mse: 0.6460\n",
      "Epoch 57/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.7178 - mse: 0.9246 - val_loss: 0.5675 - val_mse: 0.6195\n",
      "Epoch 58/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6118 - mse: 0.7356 - val_loss: 0.5567 - val_mse: 0.5983\n",
      "Epoch 59/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6141 - mse: 0.7140 - val_loss: 0.5437 - val_mse: 0.5723\n",
      "Epoch 60/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6850 - mse: 0.8331 - val_loss: 0.5320 - val_mse: 0.5499\n",
      "Epoch 61/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6250 - mse: 0.7105 - val_loss: 0.5199 - val_mse: 0.5268\n",
      "Epoch 62/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6014 - mse: 0.6664 - val_loss: 0.5120 - val_mse: 0.5086\n",
      "Epoch 63/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5991 - mse: 0.6433 - val_loss: 0.4979 - val_mse: 0.4850\n",
      "Epoch 64/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6193 - mse: 0.6752 - val_loss: 0.4881 - val_mse: 0.4654\n",
      "Epoch 65/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5621 - mse: 0.5997 - val_loss: 0.4795 - val_mse: 0.4477\n",
      "Epoch 66/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5394 - mse: 0.5355 - val_loss: 0.4715 - val_mse: 0.4317\n",
      "Epoch 67/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5790 - mse: 0.5932 - val_loss: 0.4637 - val_mse: 0.4118\n",
      "Epoch 68/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5159 - mse: 0.5023 - val_loss: 0.4559 - val_mse: 0.3970\n",
      "Epoch 69/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5089 - mse: 0.4755 - val_loss: 0.4477 - val_mse: 0.3823\n",
      "Epoch 70/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.5048 - mse: 0.4911 - val_loss: 0.4406 - val_mse: 0.3663\n",
      "Epoch 71/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4725 - mse: 0.4111 - val_loss: 0.4348 - val_mse: 0.3494\n",
      "Epoch 72/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4713 - mse: 0.4081 - val_loss: 0.4281 - val_mse: 0.3338\n",
      "Epoch 73/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4767 - mse: 0.4017 - val_loss: 0.4213 - val_mse: 0.3198\n",
      "Epoch 74/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4123 - mse: 0.3260 - val_loss: 0.4146 - val_mse: 0.3053\n",
      "Epoch 75/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4537 - mse: 0.3639 - val_loss: 0.4075 - val_mse: 0.2922\n",
      "Epoch 76/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4460 - mse: 0.3528 - val_loss: 0.4014 - val_mse: 0.2803\n",
      "Epoch 77/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4111 - mse: 0.3158 - val_loss: 0.3961 - val_mse: 0.2696\n",
      "Epoch 78/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4050 - mse: 0.3139 - val_loss: 0.3894 - val_mse: 0.2594\n",
      "Epoch 79/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3924 - mse: 0.2951 - val_loss: 0.3818 - val_mse: 0.2481\n",
      "Epoch 80/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4066 - mse: 0.2976 - val_loss: 0.3731 - val_mse: 0.2362\n",
      "Epoch 81/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3806 - mse: 0.2682 - val_loss: 0.3651 - val_mse: 0.2257\n",
      "Epoch 82/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3198 - mse: 0.1981 - val_loss: 0.3567 - val_mse: 0.2157\n",
      "Epoch 83/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3346 - mse: 0.2241 - val_loss: 0.3500 - val_mse: 0.2084\n",
      "Epoch 84/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3351 - mse: 0.2201 - val_loss: 0.3435 - val_mse: 0.2014\n",
      "Epoch 85/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3150 - mse: 0.1927 - val_loss: 0.3361 - val_mse: 0.1934\n",
      "Epoch 86/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3263 - mse: 0.2063 - val_loss: 0.3279 - val_mse: 0.1853\n",
      "Epoch 87/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3195 - mse: 0.1993 - val_loss: 0.3195 - val_mse: 0.1776\n",
      "Epoch 88/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3016 - mse: 0.1791 - val_loss: 0.3124 - val_mse: 0.1711\n",
      "Epoch 89/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2963 - mse: 0.1666 - val_loss: 0.3067 - val_mse: 0.1655\n",
      "Epoch 90/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2862 - mse: 0.1592 - val_loss: 0.3019 - val_mse: 0.1603\n",
      "Epoch 91/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3125 - mse: 0.1805 - val_loss: 0.2958 - val_mse: 0.1545\n",
      "Epoch 92/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3108 - mse: 0.1720 - val_loss: 0.2892 - val_mse: 0.1483\n",
      "Epoch 93/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2899 - mse: 0.1674 - val_loss: 0.2837 - val_mse: 0.1434\n",
      "Epoch 94/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2682 - mse: 0.1445 - val_loss: 0.2796 - val_mse: 0.1397\n",
      "Epoch 95/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2797 - mse: 0.1481 - val_loss: 0.2745 - val_mse: 0.1357\n",
      "Epoch 96/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2713 - mse: 0.1369 - val_loss: 0.2681 - val_mse: 0.1306\n",
      "Epoch 97/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2650 - mse: 0.1361 - val_loss: 0.2617 - val_mse: 0.1260\n",
      "Epoch 98/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2683 - mse: 0.1383 - val_loss: 0.2582 - val_mse: 0.1240\n",
      "Epoch 99/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2769 - mse: 0.1436 - val_loss: 0.2532 - val_mse: 0.1205\n",
      "Epoch 100/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2649 - mse: 0.1283 - val_loss: 0.2469 - val_mse: 0.1165\n",
      "Epoch 101/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2347 - mse: 0.1065 - val_loss: 0.2430 - val_mse: 0.1134\n",
      "Epoch 102/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2427 - mse: 0.1157 - val_loss: 0.2359 - val_mse: 0.1093\n",
      "Epoch 103/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2260 - mse: 0.0978 - val_loss: 0.2328 - val_mse: 0.1064\n",
      "Epoch 104/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2547 - mse: 0.1103 - val_loss: 0.2287 - val_mse: 0.1034\n",
      "Epoch 105/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2310 - mse: 0.0993 - val_loss: 0.2211 - val_mse: 0.0991\n",
      "Epoch 106/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2283 - mse: 0.0996 - val_loss: 0.2164 - val_mse: 0.0962\n",
      "Epoch 107/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2382 - mse: 0.1006 - val_loss: 0.2137 - val_mse: 0.0941\n",
      "Epoch 108/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2221 - mse: 0.0954 - val_loss: 0.2099 - val_mse: 0.0920\n",
      "Epoch 109/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2401 - mse: 0.1027 - val_loss: 0.2051 - val_mse: 0.0898\n",
      "Epoch 110/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1935 - mse: 0.0727 - val_loss: 0.2044 - val_mse: 0.0887\n",
      "Epoch 111/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2135 - mse: 0.0845 - val_loss: 0.1984 - val_mse: 0.0860\n",
      "Epoch 112/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2031 - mse: 0.0741 - val_loss: 0.1943 - val_mse: 0.0829\n",
      "Epoch 113/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2011 - mse: 0.0759 - val_loss: 0.1901 - val_mse: 0.0805\n",
      "Epoch 114/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1984 - mse: 0.0763 - val_loss: 0.1884 - val_mse: 0.0787\n",
      "Epoch 115/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2002 - mse: 0.0724 - val_loss: 0.1845 - val_mse: 0.0764\n",
      "Epoch 116/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2094 - mse: 0.0847 - val_loss: 0.1819 - val_mse: 0.0744\n",
      "Epoch 117/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1800 - mse: 0.0641 - val_loss: 0.1777 - val_mse: 0.0728\n",
      "Epoch 118/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1916 - mse: 0.0705 - val_loss: 0.1735 - val_mse: 0.0706\n",
      "Epoch 119/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1774 - mse: 0.0580 - val_loss: 0.1722 - val_mse: 0.0695\n",
      "Epoch 120/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1805 - mse: 0.0618 - val_loss: 0.1717 - val_mse: 0.0690\n",
      "Epoch 121/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1823 - mse: 0.0654 - val_loss: 0.1667 - val_mse: 0.0673\n",
      "Epoch 122/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1722 - mse: 0.0571 - val_loss: 0.1670 - val_mse: 0.0667\n",
      "Epoch 123/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1744 - mse: 0.0565 - val_loss: 0.1631 - val_mse: 0.0653\n",
      "Epoch 124/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1560 - mse: 0.0498 - val_loss: 0.1615 - val_mse: 0.0638\n",
      "Epoch 125/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1575 - mse: 0.0493 - val_loss: 0.1599 - val_mse: 0.0628\n",
      "Epoch 126/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1565 - mse: 0.0453 - val_loss: 0.1588 - val_mse: 0.0621\n",
      "Epoch 127/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1708 - mse: 0.0524 - val_loss: 0.1567 - val_mse: 0.0611\n",
      "Epoch 128/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1749 - mse: 0.0581 - val_loss: 0.1538 - val_mse: 0.0602\n",
      "Epoch 129/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1631 - mse: 0.0497 - val_loss: 0.1523 - val_mse: 0.0595\n",
      "Epoch 130/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1636 - mse: 0.0533 - val_loss: 0.1515 - val_mse: 0.0597\n",
      "Epoch 131/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1542 - mse: 0.0451 - val_loss: 0.1493 - val_mse: 0.0589\n",
      "Epoch 132/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1444 - mse: 0.0405 - val_loss: 0.1485 - val_mse: 0.0581\n",
      "Epoch 133/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1472 - mse: 0.0394 - val_loss: 0.1455 - val_mse: 0.0567\n",
      "Epoch 134/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1517 - mse: 0.0432 - val_loss: 0.1436 - val_mse: 0.0556\n",
      "Epoch 135/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1527 - mse: 0.0437 - val_loss: 0.1420 - val_mse: 0.0549\n",
      "Epoch 136/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1582 - mse: 0.0473 - val_loss: 0.1414 - val_mse: 0.0551\n",
      "Epoch 137/250\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1348 - mse: 0.0363 - val_loss: 0.1409 - val_mse: 0.0539\n",
      "Epoch 138/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1428 - mse: 0.0420 - val_loss: 0.1402 - val_mse: 0.0532\n",
      "Epoch 139/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1337 - mse: 0.0365 - val_loss: 0.1392 - val_mse: 0.0527\n",
      "Epoch 140/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1322 - mse: 0.0346 - val_loss: 0.1380 - val_mse: 0.0522\n",
      "Epoch 141/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1414 - mse: 0.0399 - val_loss: 0.1372 - val_mse: 0.0516\n",
      "Epoch 142/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1583 - mse: 0.0458 - val_loss: 0.1368 - val_mse: 0.0507\n",
      "Epoch 143/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1361 - mse: 0.0355 - val_loss: 0.1373 - val_mse: 0.0497\n",
      "Epoch 144/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1430 - mse: 0.0412 - val_loss: 0.1349 - val_mse: 0.0497\n",
      "Epoch 145/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1294 - mse: 0.0316 - val_loss: 0.1339 - val_mse: 0.0498\n",
      "Epoch 146/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1397 - mse: 0.0397 - val_loss: 0.1337 - val_mse: 0.0487\n",
      "Epoch 147/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1297 - mse: 0.0347 - val_loss: 0.1341 - val_mse: 0.0478\n",
      "Epoch 148/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1304 - mse: 0.0326 - val_loss: 0.1328 - val_mse: 0.0474\n",
      "Epoch 149/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1295 - mse: 0.0363 - val_loss: 0.1318 - val_mse: 0.0467\n",
      "Epoch 150/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1217 - mse: 0.0313 - val_loss: 0.1310 - val_mse: 0.0458\n",
      "Epoch 151/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1315 - mse: 0.0339 - val_loss: 0.1295 - val_mse: 0.0464\n",
      "Epoch 152/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1269 - mse: 0.0335 - val_loss: 0.1291 - val_mse: 0.0461\n",
      "Epoch 153/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1337 - mse: 0.0374 - val_loss: 0.1289 - val_mse: 0.0451\n",
      "Epoch 154/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1338 - mse: 0.0361 - val_loss: 0.1290 - val_mse: 0.0439\n",
      "Epoch 155/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1180 - mse: 0.0301 - val_loss: 0.1290 - val_mse: 0.0440\n",
      "Epoch 156/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1270 - mse: 0.0341 - val_loss: 0.1290 - val_mse: 0.0437\n",
      "Epoch 157/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1313 - mse: 0.0343 - val_loss: 0.1289 - val_mse: 0.0433\n",
      "Epoch 158/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1296 - mse: 0.0342 - val_loss: 0.1276 - val_mse: 0.0426\n",
      "Epoch 159/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1179 - mse: 0.0269 - val_loss: 0.1266 - val_mse: 0.0426\n",
      "Epoch 160/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1326 - mse: 0.0397 - val_loss: 0.1263 - val_mse: 0.0425\n",
      "Epoch 161/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1168 - mse: 0.0273 - val_loss: 0.1264 - val_mse: 0.0419\n",
      "Epoch 162/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1294 - mse: 0.0356 - val_loss: 0.1260 - val_mse: 0.0413\n",
      "Epoch 163/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1146 - mse: 0.0277 - val_loss: 0.1265 - val_mse: 0.0407\n",
      "Epoch 164/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1276 - mse: 0.0319 - val_loss: 0.1256 - val_mse: 0.0411\n",
      "Epoch 165/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1192 - mse: 0.0274 - val_loss: 0.1251 - val_mse: 0.0407\n",
      "Epoch 166/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1233 - mse: 0.0297 - val_loss: 0.1250 - val_mse: 0.0400\n",
      "Epoch 167/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1214 - mse: 0.0292 - val_loss: 0.1243 - val_mse: 0.0397\n",
      "Epoch 168/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1125 - mse: 0.0270 - val_loss: 0.1240 - val_mse: 0.0395\n",
      "Epoch 169/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1163 - mse: 0.0285 - val_loss: 0.1235 - val_mse: 0.0397\n",
      "Epoch 170/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1284 - mse: 0.0378 - val_loss: 0.1226 - val_mse: 0.0391\n",
      "Epoch 171/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1148 - mse: 0.0272 - val_loss: 0.1230 - val_mse: 0.0383\n",
      "Epoch 172/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1089 - mse: 0.0256 - val_loss: 0.1221 - val_mse: 0.0377\n",
      "Epoch 173/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1189 - mse: 0.0277 - val_loss: 0.1225 - val_mse: 0.0376\n",
      "Epoch 174/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1308 - mse: 0.0344 - val_loss: 0.1223 - val_mse: 0.0371\n",
      "Epoch 175/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1135 - mse: 0.0264 - val_loss: 0.1222 - val_mse: 0.0368\n",
      "Epoch 176/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1144 - mse: 0.0258 - val_loss: 0.1215 - val_mse: 0.0363\n",
      "Epoch 177/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1222 - mse: 0.0317 - val_loss: 0.1213 - val_mse: 0.0363\n",
      "Epoch 178/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1149 - mse: 0.0263 - val_loss: 0.1206 - val_mse: 0.0364\n",
      "Epoch 179/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1208 - mse: 0.0321 - val_loss: 0.1200 - val_mse: 0.0354\n",
      "Epoch 180/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1258 - mse: 0.0302 - val_loss: 0.1204 - val_mse: 0.0347\n",
      "Epoch 181/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1212 - mse: 0.0295 - val_loss: 0.1196 - val_mse: 0.0342\n",
      "Epoch 182/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1146 - mse: 0.0275 - val_loss: 0.1194 - val_mse: 0.0338\n",
      "Epoch 183/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1165 - mse: 0.0261 - val_loss: 0.1193 - val_mse: 0.0336\n",
      "Epoch 184/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1137 - mse: 0.0260 - val_loss: 0.1185 - val_mse: 0.0332\n",
      "Epoch 185/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1233 - mse: 0.0330 - val_loss: 0.1197 - val_mse: 0.0343\n",
      "Epoch 186/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1221 - mse: 0.0317 - val_loss: 0.1178 - val_mse: 0.0328\n",
      "Epoch 187/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1138 - mse: 0.0256 - val_loss: 0.1174 - val_mse: 0.0317\n",
      "Epoch 188/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1200 - mse: 0.0277 - val_loss: 0.1176 - val_mse: 0.0319\n",
      "Epoch 189/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1156 - mse: 0.0289 - val_loss: 0.1180 - val_mse: 0.0322\n",
      "Epoch 190/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1129 - mse: 0.0247 - val_loss: 0.1186 - val_mse: 0.0320\n",
      "Epoch 191/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1179 - mse: 0.0300 - val_loss: 0.1179 - val_mse: 0.0312\n",
      "Epoch 192/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1071 - mse: 0.0230 - val_loss: 0.1172 - val_mse: 0.0312\n",
      "Epoch 193/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1129 - mse: 0.0250 - val_loss: 0.1169 - val_mse: 0.0308\n",
      "Epoch 194/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1236 - mse: 0.0296 - val_loss: 0.1166 - val_mse: 0.0309\n",
      "Epoch 195/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1165 - mse: 0.0275 - val_loss: 0.1161 - val_mse: 0.0300\n",
      "Epoch 196/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1209 - mse: 0.0285 - val_loss: 0.1173 - val_mse: 0.0304\n",
      "Epoch 197/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1066 - mse: 0.0220 - val_loss: 0.1175 - val_mse: 0.0310\n",
      "Epoch 198/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1142 - mse: 0.0251 - val_loss: 0.1181 - val_mse: 0.0309\n",
      "Epoch 199/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1158 - mse: 0.0291 - val_loss: 0.1177 - val_mse: 0.0298\n",
      "Epoch 200/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1272 - mse: 0.0325 - val_loss: 0.1168 - val_mse: 0.0297\n",
      "Epoch 201/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1137 - mse: 0.0246 - val_loss: 0.1164 - val_mse: 0.0302\n",
      "Epoch 202/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1126 - mse: 0.0272 - val_loss: 0.1157 - val_mse: 0.0294\n",
      "Epoch 203/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1110 - mse: 0.0229 - val_loss: 0.1161 - val_mse: 0.0288\n",
      "Epoch 204/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1069 - mse: 0.0223 - val_loss: 0.1153 - val_mse: 0.0289\n",
      "Epoch 205/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1155 - mse: 0.0268 - val_loss: 0.1157 - val_mse: 0.0287\n",
      "Epoch 206/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1080 - mse: 0.0225 - val_loss: 0.1153 - val_mse: 0.0288\n",
      "Epoch 207/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1099 - mse: 0.0227 - val_loss: 0.1153 - val_mse: 0.0285\n",
      "Epoch 208/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1080 - mse: 0.0218 - val_loss: 0.1153 - val_mse: 0.0280\n",
      "Epoch 209/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1091 - mse: 0.0230 - val_loss: 0.1151 - val_mse: 0.0281\n",
      "Epoch 210/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1081 - mse: 0.0237 - val_loss: 0.1146 - val_mse: 0.0282\n",
      "Epoch 211/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1150 - mse: 0.0259 - val_loss: 0.1144 - val_mse: 0.0281\n",
      "Epoch 212/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1222 - mse: 0.0279 - val_loss: 0.1141 - val_mse: 0.0280\n",
      "Epoch 213/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1108 - mse: 0.0225 - val_loss: 0.1141 - val_mse: 0.0273\n",
      "Epoch 214/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1086 - mse: 0.0226 - val_loss: 0.1137 - val_mse: 0.0274\n",
      "Epoch 215/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1185 - mse: 0.0274 - val_loss: 0.1143 - val_mse: 0.0273\n",
      "Epoch 216/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1207 - mse: 0.0294 - val_loss: 0.1154 - val_mse: 0.0277\n",
      "Epoch 217/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1146 - mse: 0.0257 - val_loss: 0.1146 - val_mse: 0.0276\n",
      "Epoch 218/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1106 - mse: 0.0245 - val_loss: 0.1135 - val_mse: 0.0275\n",
      "Epoch 219/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1093 - mse: 0.0229 - val_loss: 0.1125 - val_mse: 0.0268\n",
      "Epoch 220/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1157 - mse: 0.0261 - val_loss: 0.1123 - val_mse: 0.0264\n",
      "Epoch 221/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1208 - mse: 0.0289 - val_loss: 0.1141 - val_mse: 0.0270\n",
      "Epoch 222/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1169 - mse: 0.0278 - val_loss: 0.1153 - val_mse: 0.0276\n",
      "Epoch 223/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1155 - mse: 0.0247 - val_loss: 0.1147 - val_mse: 0.0270\n",
      "Epoch 224/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1109 - mse: 0.0224 - val_loss: 0.1140 - val_mse: 0.0265\n",
      "Epoch 225/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1120 - mse: 0.0273 - val_loss: 0.1129 - val_mse: 0.0262\n",
      "Epoch 226/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1139 - mse: 0.0242 - val_loss: 0.1123 - val_mse: 0.0258\n",
      "Epoch 227/250\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1012 - mse: 0.0201 - val_loss: 0.1123 - val_mse: 0.0256\n",
      "Epoch 228/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1081 - mse: 0.0224 - val_loss: 0.1134 - val_mse: 0.0254\n",
      "Epoch 229/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1094 - mse: 0.0240 - val_loss: 0.1137 - val_mse: 0.0259\n",
      "Epoch 230/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1135 - mse: 0.0275 - val_loss: 0.1128 - val_mse: 0.0257\n",
      "Epoch 231/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1169 - mse: 0.0254 - val_loss: 0.1116 - val_mse: 0.0250\n",
      "Epoch 232/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1138 - mse: 0.0221 - val_loss: 0.1113 - val_mse: 0.0249\n",
      "Epoch 233/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1187 - mse: 0.0263 - val_loss: 0.1117 - val_mse: 0.0250\n",
      "Epoch 234/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1156 - mse: 0.0234 - val_loss: 0.1124 - val_mse: 0.0253\n",
      "Epoch 235/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1070 - mse: 0.0239 - val_loss: 0.1117 - val_mse: 0.0248\n",
      "Epoch 236/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1125 - mse: 0.0261 - val_loss: 0.1112 - val_mse: 0.0244\n",
      "Epoch 237/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1061 - mse: 0.0209 - val_loss: 0.1117 - val_mse: 0.0249\n",
      "Epoch 238/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1101 - mse: 0.0243 - val_loss: 0.1115 - val_mse: 0.0246\n",
      "Epoch 239/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1136 - mse: 0.0255 - val_loss: 0.1117 - val_mse: 0.0242\n",
      "Epoch 240/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1114 - mse: 0.0257 - val_loss: 0.1119 - val_mse: 0.0244\n",
      "Epoch 241/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1113 - mse: 0.0238 - val_loss: 0.1113 - val_mse: 0.0241\n",
      "Epoch 242/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1117 - mse: 0.0245 - val_loss: 0.1123 - val_mse: 0.0251\n",
      "Epoch 243/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1110 - mse: 0.0245 - val_loss: 0.1124 - val_mse: 0.0245\n",
      "Epoch 244/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1139 - mse: 0.0262 - val_loss: 0.1110 - val_mse: 0.0234\n",
      "Epoch 245/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1105 - mse: 0.0237 - val_loss: 0.1110 - val_mse: 0.0237\n",
      "Epoch 246/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1066 - mse: 0.0215 - val_loss: 0.1136 - val_mse: 0.0248\n",
      "Epoch 247/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1152 - mse: 0.0251 - val_loss: 0.1126 - val_mse: 0.0238\n",
      "Epoch 248/250\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1062 - mse: 0.0199 - val_loss: 0.1112 - val_mse: 0.0236\n",
      "Epoch 249/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1016 - mse: 0.0212 - val_loss: 0.1102 - val_mse: 0.0233\n",
      "Epoch 250/250\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1104 - mse: 0.0237 - val_loss: 0.1098 - val_mse: 0.0232\n"
     ]
    }
   ],
   "source": [
    "reg=Sequential()\n",
    "reg.add(Dense(units=5,kernel_initializer='he_uniform',activation='relu',input_dim=4))\n",
    "reg.add(Dense(units=4,kernel_initializer='he_uniform',activation='relu'))\n",
    "reg.add(Dense(units=4,kernel_initializer='he_uniform',activation='relu'))\n",
    "reg.add(Dense(units=1,kernel_initializer='he_uniform',activation='linear'))\n",
    "\n",
    "reg.compile(optimizer = 'adam', loss ='mean_absolute_error', metrics = ['mse'])\n",
    "model=reg.fit(X_train, y_train,validation_data=(X_test,y_test),epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(model):\n",
    "    plt.figure(figsize=(7,5.5))\n",
    "    plt.plot(model.history['loss'],label='loss')\n",
    "    plt.plot(model.history['val_loss'],label='val_loss')\n",
    "    plt.ylim([0,1.5])\n",
    "    plt.xlim([0,120])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Model loss')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    \n",
    "plot_loss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1098 - mse: 0.0232\n"
     ]
    }
   ],
   "source": [
    "loss,mae=reg.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.600610</td>\n",
       "      <td>8.277471</td>\n",
       "      <td>2.532465</td>\n",
       "      <td>8.087834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.553978</td>\n",
       "      <td>8.023397</td>\n",
       "      <td>2.502305</td>\n",
       "      <td>7.887215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.510303</td>\n",
       "      <td>7.786551</td>\n",
       "      <td>2.477019</td>\n",
       "      <td>7.690784</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.472559</td>\n",
       "      <td>7.568190</td>\n",
       "      <td>2.450308</td>\n",
       "      <td>7.488959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.431525</td>\n",
       "      <td>7.351497</td>\n",
       "      <td>2.420178</td>\n",
       "      <td>7.279510</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.109665</td>\n",
       "      <td>0.023010</td>\n",
       "      <td>0.113561</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.108930</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>0.112566</td>\n",
       "      <td>0.023812</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.108917</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.023647</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.108767</td>\n",
       "      <td>0.022418</td>\n",
       "      <td>0.110211</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.108323</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.109831</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss       mse  val_loss   val_mse  epoch\n",
       "0    2.600610  8.277471  2.532465  8.087834      0\n",
       "1    2.553978  8.023397  2.502305  7.887215      1\n",
       "2    2.510303  7.786551  2.477019  7.690784      2\n",
       "3    2.472559  7.568190  2.450308  7.488959      3\n",
       "4    2.431525  7.351497  2.420178  7.279510      4\n",
       "..        ...       ...       ...       ...    ...\n",
       "245  0.109665  0.023010  0.113561  0.024800    245\n",
       "246  0.108930  0.022724  0.112566  0.023812    246\n",
       "247  0.108917  0.022431  0.111228  0.023647    247\n",
       "248  0.108767  0.022418  0.110211  0.023332    248\n",
       "249  0.108323  0.022200  0.109831  0.023168    249\n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist=pd.DataFrame(model.history)\n",
    "hist['epoch']=model.epoch\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0445619],\n",
       "       [3.2118902],\n",
       "       [3.1570315],\n",
       "       [3.259594 ],\n",
       "       [3.4470248],\n",
       "       [3.1587272],\n",
       "       [3.322544 ],\n",
       "       [2.9152784],\n",
       "       [3.6501756],\n",
       "       [3.3008318],\n",
       "       [3.5512176],\n",
       "       [3.025166 ],\n",
       "       [3.261302 ],\n",
       "       [2.942862 ],\n",
       "       [3.3475037],\n",
       "       [3.4556756],\n",
       "       [3.6485496],\n",
       "       [2.9885373],\n",
       "       [3.6485496],\n",
       "       [3.3669004],\n",
       "       [3.3107138],\n",
       "       [2.935536 ],\n",
       "       [3.6485496],\n",
       "       [3.3205962],\n",
       "       [3.5653954],\n",
       "       [3.0398178],\n",
       "       [3.8330483],\n",
       "       [3.135356 ],\n",
       "       [3.2229643],\n",
       "       [3.6485496],\n",
       "       [3.146747 ],\n",
       "       [3.6362867],\n",
       "       [3.3255262],\n",
       "       [3.1277285],\n",
       "       [3.4040203],\n",
       "       [3.04187  ],\n",
       "       [2.9445815],\n",
       "       [3.4884338],\n",
       "       [2.9299302],\n",
       "       [2.9250126]], dtype=float32)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=reg.predict(X_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
